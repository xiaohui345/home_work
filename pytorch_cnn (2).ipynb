{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader \nimport matplotlib.pyplot as plt\nimport numpy as np","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#加载数据集并且对数据进行预处理"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 64\n# 加载数据集\ntrainset = datasets.CIFAR10(root='./data',train=True,download=True,transform=transform)\ntestset = datasets.CIFAR10(root='./data',train=False,download=True,transform=transform)\n# 并把数据集放入数据加载器中 这样就可以进行 batch 处理数据了\ntrainloader = DataLoader(trainset,batch_size=BATCH_SIZE,shuffle=True)\ntestloader = DataLoader(testset,batch_size=BATCH_SIZE,shuffle=False)","execution_count":3,"outputs":[{"output_type":"stream","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"465908cf05b0426b83dec4954aab404f"}},"metadata":{}},{"output_type":"stream","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 类别标签\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#搭建cnn\nimport torch\nimport torch.nn.functional as F\nimport torch.nn as nn\nLr = 5e-3\n\nclass Net_1(nn.Module):\n    def __init__(self):\n        super(Net_1,self).__init__()\n        #将卷积和池化层和BacthNormal组合为一个网络层\n        \n        self.conv1 = nn.Sequential(\n            nn.Conv2d(3,16,3,padding=1),\n            nn.ReLU(),\n            nn.BatchNorm2d(16),\n        )\n        # 图像的尺寸缩小半,卷积核的个数翻倍，提取更多的特征\n        \n        self.conv2 = nn.Sequential(\n            nn.Conv2d(16,32,3,padding=1),\n            nn.ReLU(),\n            nn.BatchNorm2d(32),\n            nn.MaxPool2d(2,2)\n        )\n        \n        self.conv3 = nn.Sequential(\n            nn.Conv2d(32,64,3,padding=1),\n            nn.ReLU(),\n            nn.BatchNorm2d(64),\n        )\n        \n        self.conv4 = nn.Sequential(\n            nn.Conv2d(64,128,3,padding=1),\n            nn.ReLU(),\n            nn.BatchNorm2d(128),\n            nn.MaxPool2d(2,2)\n        )\n        \n        self.conv5 = nn.Sequential(\n            nn.Conv2d(128,256,3,padding=1),\n            nn.ReLU(),\n            nn.BatchNorm2d(256),\n            nn.MaxPool2d(2,2)\n        )\n        \n        self.gap = nn.AvgPool2d(4,4)    #padding=0\n        self.fc1 = nn.Linear(256,10)\n        \n    def forward(self,x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.conv5(x)\n        x = self.gap(x)\n        x = x.view(x.size(0),-1)\n        x = F.softmax(self.fc1(x),dim=1)\n        return x ","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net_1 = Net_1()\nnet_1.cuda()\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(net_1.parameters(),lr=Lr,weight_decay=0)  # L2正则","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net_1","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"Net_1(\n  (conv1): Sequential(\n    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (conv2): Sequential(\n    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (conv3): Sequential(\n    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (conv4): Sequential(\n    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (conv5): Sequential(\n    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (gap): AvgPool2d(kernel_size=4, stride=4, padding=0)\n  (fc1): Linear(in_features=256, out_features=10, bias=True)\n)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model, criterion, optimizer, trainloader, epochs=5, log_interval=50):\n    print('----- Train Start -----')\n    train_acc = []\n    train_loss = []\n    for epoch in range(epochs):\n        #样本总数\n        total = 0\n        #识别正确的个数\n        correct = 0\n        running_loss = 0.0\n        for step, (batch_x, batch_y) in enumerate(trainloader):\n            batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n            output = model(batch_x)\n#             print('output',output,output.shape)\n            optimizer.zero_grad()\n            loss = criterion(output, batch_y)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n            \n            _,pred_label = torch.max(output.data,1) #取概率最大的数的index作为Label\n            correct += (pred_label == batch_y).sum().item() # 只有与label相等的 为1\n            total += batch_y.size(0)\n            if  step % log_interval == (log_interval-1):\n                # 50为一个mini-batches\n                # 已经训练的样本数\n                #acc\n                # mini-batches 打印一下train_acc\n                acc = 100*(correct/total)\n                ste_loss = running_loss / log_interval\n                # 记录训练准确率以输出变化曲线\n                train_acc.append(acc)\n                train_loss.append(ste_loss)\n                print('[%d, %5d,] loss: %.5f acc: %.5f'%\n                      (epoch + 1, step+1, ste_loss,acc))\n                running_loss = 0.0\n    print('----- Train Finished -----')\n    return train_acc,train_loss","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_acc ,train_loss= train(net_1, criterion, optimizer, trainloader, epochs=40, log_interval=50)","execution_count":9,"outputs":[{"output_type":"stream","text":"----- Train Start -----\n[1,    50,] loss: 2.21226 acc: 23.78125\n[1,   100,] loss: 2.14283 acc: 27.37500\n[1,   150,] loss: 2.10464 acc: 29.97917\n[1,   200,] loss: 2.09125 acc: 31.57031\n[1,   250,] loss: 2.05144 acc: 33.38750\n[1,   300,] loss: 2.04304 acc: 34.70312\n[1,   350,] loss: 2.01896 acc: 35.97321\n[1,   400,] loss: 2.00149 acc: 37.21094\n[1,   450,] loss: 1.99056 acc: 38.23958\n[1,   500,] loss: 1.98585 acc: 39.08125\n[1,   550,] loss: 1.96755 acc: 39.98295\n[1,   600,] loss: 1.94410 acc: 40.95052\n[1,   650,] loss: 1.97854 acc: 41.46154\n[1,   700,] loss: 1.93936 acc: 42.22098\n[1,   750,] loss: 1.93544 acc: 42.87292\n[2,    50,] loss: 1.91991 acc: 53.87500\n[2,   100,] loss: 1.87996 acc: 55.82812\n[2,   150,] loss: 1.92297 acc: 55.09375\n[2,   200,] loss: 1.87647 acc: 55.89063\n[2,   250,] loss: 1.88184 acc: 56.25000\n[2,   300,] loss: 1.87785 acc: 56.50521\n[2,   350,] loss: 1.85806 acc: 57.03125\n[2,   400,] loss: 1.85463 acc: 57.43359\n[2,   450,] loss: 1.87333 acc: 57.56944\n[2,   500,] loss: 1.85457 acc: 57.89062\n[2,   550,] loss: 1.86891 acc: 57.99716\n[2,   600,] loss: 1.84249 acc: 58.30729\n[2,   650,] loss: 1.85151 acc: 58.49279\n[2,   700,] loss: 1.86087 acc: 58.56473\n[2,   750,] loss: 1.85515 acc: 58.68542\n[3,    50,] loss: 1.82275 acc: 63.96875\n[3,   100,] loss: 1.81650 acc: 64.15625\n[3,   150,] loss: 1.83542 acc: 63.55208\n[3,   200,] loss: 1.83337 acc: 63.36719\n[3,   250,] loss: 1.81296 acc: 63.65000\n[3,   300,] loss: 1.81103 acc: 63.81771\n[3,   350,] loss: 1.81763 acc: 63.87946\n[3,   400,] loss: 1.82233 acc: 63.87500\n[3,   450,] loss: 1.80768 acc: 64.05903\n[3,   500,] loss: 1.82765 acc: 63.98438\n[3,   550,] loss: 1.79465 acc: 64.19886\n[3,   600,] loss: 1.81262 acc: 64.21875\n[3,   650,] loss: 1.81267 acc: 64.24279\n[3,   700,] loss: 1.80618 acc: 64.29688\n[3,   750,] loss: 1.81104 acc: 64.33750\n[4,    50,] loss: 1.76779 acc: 69.40625\n[4,   100,] loss: 1.78527 acc: 68.21875\n[4,   150,] loss: 1.80417 acc: 67.32292\n[4,   200,] loss: 1.78468 acc: 67.39062\n[4,   250,] loss: 1.76564 acc: 67.83125\n[4,   300,] loss: 1.77264 acc: 67.99479\n[4,   350,] loss: 1.79291 acc: 67.74554\n[4,   400,] loss: 1.77593 acc: 67.85938\n[4,   450,] loss: 1.77976 acc: 67.88542\n[4,   500,] loss: 1.75978 acc: 68.10312\n[4,   550,] loss: 1.76464 acc: 68.19886\n[4,   600,] loss: 1.77837 acc: 68.18229\n[4,   650,] loss: 1.77354 acc: 68.22596\n[4,   700,] loss: 1.76356 acc: 68.33259\n[4,   750,] loss: 1.75620 acc: 68.47083\n[5,    50,] loss: 1.76412 acc: 69.31250\n[5,   100,] loss: 1.73397 acc: 70.95312\n[5,   150,] loss: 1.73866 acc: 71.39583\n[5,   200,] loss: 1.73696 acc: 71.62500\n[5,   250,] loss: 1.74391 acc: 71.64375\n[5,   300,] loss: 1.75845 acc: 71.32812\n[5,   350,] loss: 1.74890 acc: 71.26786\n[5,   400,] loss: 1.74544 acc: 71.32812\n[5,   450,] loss: 1.75123 acc: 71.26042\n[5,   500,] loss: 1.74163 acc: 71.33750\n[5,   550,] loss: 1.75213 acc: 71.28977\n[5,   600,] loss: 1.75857 acc: 71.19010\n[5,   650,] loss: 1.73696 acc: 71.30769\n[5,   700,] loss: 1.73955 acc: 71.37277\n[5,   750,] loss: 1.73530 acc: 71.43333\n[6,    50,] loss: 1.72041 acc: 73.96875\n[6,   100,] loss: 1.72012 acc: 73.96875\n[6,   150,] loss: 1.72892 acc: 73.64583\n[6,   200,] loss: 1.72578 acc: 73.62500\n[6,   250,] loss: 1.72155 acc: 73.66875\n[6,   300,] loss: 1.73203 acc: 73.57812\n[6,   350,] loss: 1.72662 acc: 73.54464\n[6,   400,] loss: 1.73825 acc: 73.35547\n[6,   450,] loss: 1.75607 acc: 73.03819\n[6,   500,] loss: 1.72696 acc: 73.08750\n[6,   550,] loss: 1.71630 acc: 73.20739\n[6,   600,] loss: 1.71861 acc: 73.27083\n[6,   650,] loss: 1.71774 acc: 73.36058\n[6,   700,] loss: 1.71651 acc: 73.43750\n[6,   750,] loss: 1.72602 acc: 73.42917\n[7,    50,] loss: 1.69539 acc: 76.93750\n[7,   100,] loss: 1.70161 acc: 76.35938\n[7,   150,] loss: 1.69984 acc: 76.25000\n[7,   200,] loss: 1.69711 acc: 76.32031\n[7,   250,] loss: 1.70213 acc: 76.21875\n[7,   300,] loss: 1.70645 acc: 76.13021\n[7,   350,] loss: 1.69984 acc: 76.14732\n[7,   400,] loss: 1.70307 acc: 76.11719\n[7,   450,] loss: 1.69760 acc: 76.12153\n[7,   500,] loss: 1.71254 acc: 75.99688\n[7,   550,] loss: 1.70292 acc: 75.97159\n[7,   600,] loss: 1.69929 acc: 75.97135\n[7,   650,] loss: 1.70633 acc: 75.93029\n[7,   700,] loss: 1.69521 acc: 75.96652\n[7,   750,] loss: 1.70918 acc: 75.91667\n[8,    50,] loss: 1.69719 acc: 75.93750\n[8,   100,] loss: 1.67916 acc: 77.23438\n[8,   150,] loss: 1.69024 acc: 77.22917\n[8,   200,] loss: 1.68543 acc: 77.28906\n[8,   250,] loss: 1.67827 acc: 77.50000\n[8,   300,] loss: 1.68276 acc: 77.57292\n[8,   350,] loss: 1.67766 acc: 77.70089\n[8,   400,] loss: 1.68462 acc: 77.67969\n[8,   450,] loss: 1.69010 acc: 77.64583\n[8,   500,] loss: 1.68895 acc: 77.60625\n[8,   550,] loss: 1.68692 acc: 77.56534\n[8,   600,] loss: 1.68935 acc: 77.53125\n[8,   650,] loss: 1.68733 acc: 77.52404\n[8,   700,] loss: 1.68137 acc: 77.54911\n[8,   750,] loss: 1.68471 acc: 77.56667\n[9,    50,] loss: 1.66851 acc: 79.34375\n[9,   100,] loss: 1.65881 acc: 79.81250\n[9,   150,] loss: 1.65743 acc: 79.96875\n[9,   200,] loss: 1.65894 acc: 80.09375\n[9,   250,] loss: 1.65818 acc: 80.08125\n[9,   300,] loss: 1.66138 acc: 80.03125\n[9,   350,] loss: 1.66457 acc: 79.96429\n[9,   400,] loss: 1.67846 acc: 79.75391\n[9,   450,] loss: 1.65762 acc: 79.82292\n[9,   500,] loss: 1.67810 acc: 79.66875\n[9,   550,] loss: 1.68740 acc: 79.46591\n[9,   600,] loss: 1.68599 acc: 79.29688\n[9,   650,] loss: 1.65810 acc: 79.38702\n[9,   700,] loss: 1.66495 acc: 79.41518\n[9,   750,] loss: 1.66916 acc: 79.41667\n[10,    50,] loss: 1.65225 acc: 80.93750\n[10,   100,] loss: 1.65288 acc: 80.96875\n[10,   150,] loss: 1.66465 acc: 80.48958\n[10,   200,] loss: 1.65189 acc: 80.60156\n[10,   250,] loss: 1.65025 acc: 80.73125\n[10,   300,] loss: 1.65894 acc: 80.66667\n[10,   350,] loss: 1.64464 acc: 80.78571\n[10,   400,] loss: 1.66944 acc: 80.57422\n[10,   450,] loss: 1.66231 acc: 80.51042\n[10,   500,] loss: 1.65985 acc: 80.45937\n[10,   550,] loss: 1.65747 acc: 80.46023\n[10,   600,] loss: 1.66990 acc: 80.35156\n[10,   650,] loss: 1.66740 acc: 80.26683\n[10,   700,] loss: 1.64911 acc: 80.34375\n[10,   750,] loss: 1.65913 acc: 80.34583\n[11,    50,] loss: 1.64934 acc: 81.12500\n[11,   100,] loss: 1.64233 acc: 81.53125\n[11,   150,] loss: 1.63517 acc: 81.90625\n[11,   200,] loss: 1.64440 acc: 81.85938\n[11,   250,] loss: 1.64690 acc: 81.75625\n[11,   300,] loss: 1.65134 acc: 81.59375\n[11,   350,] loss: 1.65459 acc: 81.45536\n[11,   400,] loss: 1.65174 acc: 81.37109\n[11,   450,] loss: 1.64054 acc: 81.42708\n[11,   500,] loss: 1.65027 acc: 81.38437\n[11,   550,] loss: 1.65568 acc: 81.30398\n[11,   600,] loss: 1.65186 acc: 81.26302\n[11,   650,] loss: 1.64980 acc: 81.25000\n[11,   700,] loss: 1.64289 acc: 81.29018\n[11,   750,] loss: 1.63639 acc: 81.38958\n[12,    50,] loss: 1.63458 acc: 82.53125\n[12,   100,] loss: 1.62344 acc: 83.17188\n[12,   150,] loss: 1.64374 acc: 82.68750\n[12,   200,] loss: 1.63265 acc: 82.71875\n[12,   250,] loss: 1.63316 acc: 82.75625\n[12,   300,] loss: 1.62843 acc: 82.86458\n[12,   350,] loss: 1.62946 acc: 82.93750\n[12,   400,] loss: 1.64282 acc: 82.79688\n[12,   450,] loss: 1.62687 acc: 82.87153\n[12,   500,] loss: 1.63572 acc: 82.83125\n[12,   550,] loss: 1.65263 acc: 82.64205\n[12,   600,] loss: 1.64106 acc: 82.58854\n[12,   650,] loss: 1.64207 acc: 82.53125\n[12,   700,] loss: 1.63779 acc: 82.50446\n[12,   750,] loss: 1.64492 acc: 82.44583\n[13,    50,] loss: 1.62492 acc: 83.37500\n[13,   100,] loss: 1.62398 acc: 83.64062\n[13,   150,] loss: 1.63193 acc: 83.36458\n[13,   200,] loss: 1.63188 acc: 83.24219\n[13,   250,] loss: 1.64063 acc: 83.00000\n[13,   300,] loss: 1.61694 acc: 83.21875\n[13,   350,] loss: 1.61543 acc: 83.42411\n[13,   400,] loss: 1.64161 acc: 83.21875\n[13,   450,] loss: 1.62970 acc: 83.20833\n[13,   500,] loss: 1.63910 acc: 83.08125\n[13,   550,] loss: 1.61943 acc: 83.18182\n[13,   600,] loss: 1.63630 acc: 83.11458\n[13,   650,] loss: 1.63654 acc: 83.07212\n[13,   700,] loss: 1.63962 acc: 83.00893\n[13,   750,] loss: 1.62392 acc: 83.05000\n[14,    50,] loss: 1.61475 acc: 84.62500\n[14,   100,] loss: 1.61841 acc: 84.40625\n[14,   150,] loss: 1.60877 acc: 84.66667\n[14,   200,] loss: 1.61976 acc: 84.60938\n[14,   250,] loss: 1.62107 acc: 84.46250\n[14,   300,] loss: 1.62984 acc: 84.20312\n[14,   350,] loss: 1.63680 acc: 83.94196\n[14,   400,] loss: 1.64310 acc: 83.64844\n","name":"stdout"},{"output_type":"stream","text":"[14,   450,] loss: 1.61452 acc: 83.74653\n[14,   500,] loss: 1.62145 acc: 83.75938\n[14,   550,] loss: 1.63397 acc: 83.64205\n[14,   600,] loss: 1.63595 acc: 83.55729\n[14,   650,] loss: 1.62445 acc: 83.56731\n[14,   700,] loss: 1.63028 acc: 83.55357\n[14,   750,] loss: 1.62037 acc: 83.57917\n[15,    50,] loss: 1.60293 acc: 85.75000\n[15,   100,] loss: 1.61781 acc: 85.00000\n[15,   150,] loss: 1.61057 acc: 84.96875\n[15,   200,] loss: 1.61402 acc: 84.92969\n[15,   250,] loss: 1.60929 acc: 84.95625\n[15,   300,] loss: 1.61771 acc: 84.85417\n[15,   350,] loss: 1.60604 acc: 84.95089\n[15,   400,] loss: 1.62161 acc: 84.83203\n[15,   450,] loss: 1.62482 acc: 84.68750\n[15,   500,] loss: 1.63098 acc: 84.51875\n[15,   550,] loss: 1.62244 acc: 84.43750\n[15,   600,] loss: 1.61492 acc: 84.44010\n[15,   650,] loss: 1.62196 acc: 84.38942\n[15,   700,] loss: 1.61591 acc: 84.39286\n[15,   750,] loss: 1.63009 acc: 84.29167\n[16,    50,] loss: 1.60836 acc: 85.09375\n[16,   100,] loss: 1.60579 acc: 85.32812\n[16,   150,] loss: 1.61322 acc: 85.13542\n[16,   200,] loss: 1.61299 acc: 85.08594\n[16,   250,] loss: 1.60901 acc: 85.08750\n[16,   300,] loss: 1.60634 acc: 85.12500\n[16,   350,] loss: 1.60316 acc: 85.20982\n[16,   400,] loss: 1.61138 acc: 85.18359\n[16,   450,] loss: 1.60213 acc: 85.24653\n[16,   500,] loss: 1.61089 acc: 85.22187\n[16,   550,] loss: 1.61508 acc: 85.19318\n[16,   600,] loss: 1.61307 acc: 85.15365\n[16,   650,] loss: 1.60844 acc: 85.15385\n[16,   700,] loss: 1.62969 acc: 85.01116\n[16,   750,] loss: 1.61249 acc: 85.00000\n[17,    50,] loss: 1.59622 acc: 86.34375\n[17,   100,] loss: 1.59628 acc: 86.42188\n[17,   150,] loss: 1.59920 acc: 86.35417\n[17,   200,] loss: 1.60300 acc: 86.22656\n[17,   250,] loss: 1.60303 acc: 86.16250\n[17,   300,] loss: 1.60406 acc: 86.09896\n[17,   350,] loss: 1.60912 acc: 85.96875\n[17,   400,] loss: 1.60732 acc: 85.89844\n[17,   450,] loss: 1.61049 acc: 85.79861\n[17,   500,] loss: 1.60302 acc: 85.80625\n[17,   550,] loss: 1.60130 acc: 85.82102\n[17,   600,] loss: 1.60406 acc: 85.79688\n[17,   650,] loss: 1.61069 acc: 85.72837\n[17,   700,] loss: 1.60953 acc: 85.68080\n[17,   750,] loss: 1.61544 acc: 85.60625\n[18,    50,] loss: 1.58697 acc: 87.46875\n[18,   100,] loss: 1.59188 acc: 87.25000\n[18,   150,] loss: 1.59317 acc: 87.08333\n[18,   200,] loss: 1.59917 acc: 86.85156\n[18,   250,] loss: 1.59509 acc: 86.80000\n[18,   300,] loss: 1.59916 acc: 86.68750\n[18,   350,] loss: 1.60218 acc: 86.53571\n[18,   400,] loss: 1.60404 acc: 86.42188\n[18,   450,] loss: 1.59365 acc: 86.46875\n[18,   500,] loss: 1.59899 acc: 86.44375\n[18,   550,] loss: 1.64658 acc: 85.99716\n[18,   600,] loss: 1.62387 acc: 85.79167\n[18,   650,] loss: 1.60660 acc: 85.76202\n[18,   700,] loss: 1.61404 acc: 85.68080\n[18,   750,] loss: 1.61156 acc: 85.63542\n[19,    50,] loss: 1.58907 acc: 87.21875\n[19,   100,] loss: 1.59202 acc: 86.93750\n[19,   150,] loss: 1.59126 acc: 86.96875\n[19,   200,] loss: 1.60480 acc: 86.57812\n[19,   250,] loss: 1.59565 acc: 86.55625\n[19,   300,] loss: 1.59714 acc: 86.51562\n[19,   350,] loss: 1.59937 acc: 86.45982\n[19,   400,] loss: 1.60003 acc: 86.41797\n[19,   450,] loss: 1.59802 acc: 86.40972\n[19,   500,] loss: 1.59550 acc: 86.42812\n[19,   550,] loss: 1.59559 acc: 86.42898\n[19,   600,] loss: 1.60597 acc: 86.36198\n[19,   650,] loss: 1.61266 acc: 86.23798\n[19,   700,] loss: 1.60253 acc: 86.20089\n[19,   750,] loss: 1.60833 acc: 86.13333\n[20,    50,] loss: 1.59958 acc: 86.28125\n[20,   100,] loss: 1.58191 acc: 87.07812\n[20,   150,] loss: 1.58763 acc: 87.21875\n[20,   200,] loss: 1.58284 acc: 87.34375\n[20,   250,] loss: 1.58530 acc: 87.37500\n[20,   300,] loss: 1.58970 acc: 87.34375\n[20,   350,] loss: 1.59259 acc: 87.29464\n[20,   400,] loss: 1.59556 acc: 87.17578\n[20,   450,] loss: 1.58347 acc: 87.22569\n[20,   500,] loss: 1.58753 acc: 87.21875\n[20,   550,] loss: 1.59810 acc: 87.12500\n[20,   600,] loss: 1.59308 acc: 87.11198\n[20,   650,] loss: 1.60218 acc: 87.00962\n[20,   700,] loss: 1.60960 acc: 86.88170\n[20,   750,] loss: 1.59602 acc: 86.84583\n[21,    50,] loss: 1.58453 acc: 87.59375\n[21,   100,] loss: 1.58905 acc: 87.43750\n[21,   150,] loss: 1.56977 acc: 88.03125\n[21,   200,] loss: 1.58795 acc: 87.85156\n[21,   250,] loss: 1.58913 acc: 87.68750\n[21,   300,] loss: 1.60139 acc: 87.38542\n[21,   350,] loss: 1.57302 acc: 87.60268\n[21,   400,] loss: 1.57323 acc: 87.74219\n[21,   450,] loss: 1.59175 acc: 87.64931\n[21,   500,] loss: 1.59314 acc: 87.56562\n[21,   550,] loss: 1.59861 acc: 87.42614\n[21,   600,] loss: 1.59377 acc: 87.38021\n[21,   650,] loss: 1.57605 acc: 87.45433\n[21,   700,] loss: 1.58242 acc: 87.49107\n[21,   750,] loss: 1.59226 acc: 87.45625\n[22,    50,] loss: 1.58293 acc: 87.84375\n[22,   100,] loss: 1.57507 acc: 88.18750\n[22,   150,] loss: 1.57853 acc: 88.20833\n[22,   200,] loss: 1.57954 acc: 88.18750\n[22,   250,] loss: 1.57501 acc: 88.27500\n[22,   300,] loss: 1.58429 acc: 88.18750\n[22,   350,] loss: 1.57354 acc: 88.25893\n[22,   400,] loss: 1.58473 acc: 88.17578\n[22,   450,] loss: 1.58403 acc: 88.12500\n[22,   500,] loss: 1.58579 acc: 88.05312\n[22,   550,] loss: 1.58943 acc: 87.97159\n[22,   600,] loss: 1.58426 acc: 87.95052\n[22,   650,] loss: 1.58192 acc: 87.93269\n[22,   700,] loss: 1.59057 acc: 87.87500\n[22,   750,] loss: 1.59346 acc: 87.79375\n[23,    50,] loss: 1.57927 acc: 88.09375\n[23,   100,] loss: 1.58382 acc: 87.93750\n[23,   150,] loss: 1.57569 acc: 88.17708\n[23,   200,] loss: 1.57473 acc: 88.24219\n[23,   250,] loss: 1.58047 acc: 88.20625\n[23,   300,] loss: 1.58233 acc: 88.16667\n[23,   350,] loss: 1.58351 acc: 88.09375\n[23,   400,] loss: 1.58862 acc: 87.96484\n[23,   450,] loss: 1.58344 acc: 87.95486\n[23,   500,] loss: 1.58014 acc: 87.97500\n[23,   550,] loss: 1.57778 acc: 88.00568\n[23,   600,] loss: 1.57242 acc: 88.08854\n[23,   650,] loss: 1.59012 acc: 88.01202\n[23,   700,] loss: 1.57901 acc: 88.02009\n[23,   750,] loss: 1.58493 acc: 87.97292\n[24,    50,] loss: 1.58365 acc: 87.65625\n[24,   100,] loss: 1.56926 acc: 88.50000\n[24,   150,] loss: 1.56695 acc: 88.81250\n[24,   200,] loss: 1.56471 acc: 89.00781\n[24,   250,] loss: 1.57879 acc: 88.84375\n[24,   300,] loss: 1.57909 acc: 88.71875\n[24,   350,] loss: 1.57717 acc: 88.65179\n[24,   400,] loss: 1.58546 acc: 88.48828\n[24,   450,] loss: 1.58303 acc: 88.41319\n[24,   500,] loss: 1.58007 acc: 88.38438\n[24,   550,] loss: 1.58247 acc: 88.31818\n[24,   600,] loss: 1.59071 acc: 88.20833\n[24,   650,] loss: 1.58120 acc: 88.18990\n[24,   700,] loss: 1.58407 acc: 88.15179\n[24,   750,] loss: 1.57939 acc: 88.15833\n[25,    50,] loss: 1.57232 acc: 88.96875\n[25,   100,] loss: 1.56414 acc: 89.37500\n[25,   150,] loss: 1.56954 acc: 89.29167\n[25,   200,] loss: 1.57267 acc: 89.21875\n[25,   250,] loss: 1.57614 acc: 89.06250\n[25,   300,] loss: 1.59870 acc: 88.58333\n[25,   350,] loss: 1.56642 acc: 88.71875\n[25,   400,] loss: 1.58426 acc: 88.60156\n[25,   450,] loss: 1.58111 acc: 88.53472\n[25,   500,] loss: 1.57057 acc: 88.58125\n[25,   550,] loss: 1.57767 acc: 88.56250\n[25,   600,] loss: 1.58150 acc: 88.51042\n[25,   650,] loss: 1.58408 acc: 88.44952\n[25,   700,] loss: 1.58416 acc: 88.40179\n[25,   750,] loss: 1.57537 acc: 88.41250\n[26,    50,] loss: 1.56590 acc: 89.59375\n[26,   100,] loss: 1.56303 acc: 89.71875\n[26,   150,] loss: 1.57667 acc: 89.27083\n[26,   200,] loss: 1.55838 acc: 89.52344\n[26,   250,] loss: 1.57343 acc: 89.34375\n[26,   300,] loss: 1.57167 acc: 89.28646\n[26,   350,] loss: 1.57227 acc: 89.22321\n[26,   400,] loss: 1.56175 acc: 89.31250\n[26,   450,] loss: 1.56509 acc: 89.33333\n[26,   500,] loss: 1.57666 acc: 89.22500\n[26,   550,] loss: 1.57193 acc: 89.19886\n[26,   600,] loss: 1.57209 acc: 89.17188\n[26,   650,] loss: 1.58175 acc: 89.07692\n[26,   700,] loss: 1.57606 acc: 89.04241\n[26,   750,] loss: 1.58142 acc: 88.96875\n[27,    50,] loss: 1.56916 acc: 89.18750\n[27,   100,] loss: 1.55427 acc: 89.96875\n[27,   150,] loss: 1.56779 acc: 89.70833\n[27,   200,] loss: 1.56846 acc: 89.56250\n[27,   250,] loss: 1.55968 acc: 89.71250\n[27,   300,] loss: 1.57689 acc: 89.48438\n[27,   350,] loss: 1.56727 acc: 89.48214\n[27,   400,] loss: 1.56778 acc: 89.46875\n[27,   450,] loss: 1.56087 acc: 89.51736\n[27,   500,] loss: 1.56574 acc: 89.54062\n[27,   550,] loss: 1.56562 acc: 89.53409\n[27,   600,] loss: 1.57695 acc: 89.44010\n[27,   650,] loss: 1.57311 acc: 89.38702\n","name":"stdout"},{"output_type":"stream","text":"[27,   700,] loss: 1.57156 acc: 89.35491\n[27,   750,] loss: 1.57467 acc: 89.30000\n[28,    50,] loss: 1.57123 acc: 89.03125\n[28,   100,] loss: 1.56557 acc: 89.26562\n[28,   150,] loss: 1.57136 acc: 89.18750\n[28,   200,] loss: 1.56460 acc: 89.30469\n[28,   250,] loss: 1.56518 acc: 89.36250\n[28,   300,] loss: 1.56751 acc: 89.33333\n[28,   350,] loss: 1.57841 acc: 89.17857\n[28,   400,] loss: 1.56490 acc: 89.23438\n[28,   450,] loss: 1.55798 acc: 89.32639\n[28,   500,] loss: 1.56732 acc: 89.32812\n[28,   550,] loss: 1.57262 acc: 89.28693\n[28,   600,] loss: 1.56585 acc: 89.30729\n[28,   650,] loss: 1.56763 acc: 89.29808\n[28,   700,] loss: 1.57961 acc: 89.20759\n[28,   750,] loss: 1.56770 acc: 89.22500\n[29,    50,] loss: 1.56350 acc: 90.00000\n[29,   100,] loss: 1.55458 acc: 90.31250\n[29,   150,] loss: 1.56401 acc: 90.11458\n[29,   200,] loss: 1.56039 acc: 90.05469\n[29,   250,] loss: 1.57253 acc: 89.78125\n[29,   300,] loss: 1.56480 acc: 89.74479\n[29,   350,] loss: 1.57142 acc: 89.63839\n[29,   400,] loss: 1.57413 acc: 89.50391\n[29,   450,] loss: 1.57005 acc: 89.45486\n[29,   500,] loss: 1.56421 acc: 89.47812\n[29,   550,] loss: 1.57201 acc: 89.42614\n[29,   600,] loss: 1.56932 acc: 89.40885\n[29,   650,] loss: 1.56078 acc: 89.46154\n[29,   700,] loss: 1.57007 acc: 89.44196\n[29,   750,] loss: 1.57602 acc: 89.37708\n[30,    50,] loss: 1.55898 acc: 90.21875\n[30,   100,] loss: 1.56377 acc: 89.95312\n[30,   150,] loss: 1.55416 acc: 90.20833\n[30,   200,] loss: 1.55389 acc: 90.31250\n[30,   250,] loss: 1.56564 acc: 90.16875\n[30,   300,] loss: 1.56320 acc: 90.10417\n[30,   350,] loss: 1.57135 acc: 89.91964\n[30,   400,] loss: 1.56102 acc: 89.94141\n[30,   450,] loss: 1.57067 acc: 89.84028\n[30,   500,] loss: 1.55842 acc: 89.90000\n[30,   550,] loss: 1.57793 acc: 89.76705\n[30,   600,] loss: 1.57560 acc: 89.67188\n[30,   650,] loss: 1.58195 acc: 89.53365\n[30,   700,] loss: 1.54923 acc: 89.65179\n[30,   750,] loss: 1.55435 acc: 89.72292\n[31,    50,] loss: 1.56876 acc: 89.09375\n[31,   100,] loss: 1.55949 acc: 89.53125\n[31,   150,] loss: 1.55628 acc: 89.82292\n[31,   200,] loss: 1.54831 acc: 90.12500\n[31,   250,] loss: 1.56098 acc: 90.08750\n[31,   300,] loss: 1.55071 acc: 90.25521\n[31,   350,] loss: 1.56012 acc: 90.22321\n[31,   400,] loss: 1.56203 acc: 90.17578\n[31,   450,] loss: 1.56389 acc: 90.11806\n[31,   500,] loss: 1.56328 acc: 90.07812\n[31,   550,] loss: 1.55972 acc: 90.08523\n[31,   600,] loss: 1.57107 acc: 89.99740\n[31,   650,] loss: 1.56917 acc: 89.93510\n[31,   700,] loss: 1.56198 acc: 89.93304\n[31,   750,] loss: 1.56061 acc: 89.93958\n[32,    50,] loss: 1.55999 acc: 89.93750\n[32,   100,] loss: 1.56786 acc: 89.64062\n[32,   150,] loss: 1.54596 acc: 90.27083\n[32,   200,] loss: 1.55687 acc: 90.28125\n[32,   250,] loss: 1.55344 acc: 90.36250\n[32,   300,] loss: 1.56698 acc: 90.18750\n[32,   350,] loss: 1.56076 acc: 90.14732\n[32,   400,] loss: 1.55664 acc: 90.19531\n[32,   450,] loss: 1.56235 acc: 90.15278\n[32,   500,] loss: 1.56024 acc: 90.13750\n[32,   550,] loss: 1.55217 acc: 90.20170\n[32,   600,] loss: 1.55603 acc: 90.23177\n[32,   650,] loss: 1.55556 acc: 90.25481\n[32,   700,] loss: 1.56717 acc: 90.19643\n[32,   750,] loss: 1.56464 acc: 90.16875\n[33,    50,] loss: 1.55225 acc: 90.75000\n[33,   100,] loss: 1.54924 acc: 90.92188\n[33,   150,] loss: 1.55210 acc: 90.92708\n[33,   200,] loss: 1.55246 acc: 90.87500\n[33,   250,] loss: 1.55820 acc: 90.78125\n[33,   300,] loss: 1.55168 acc: 90.81771\n[33,   350,] loss: 1.55206 acc: 90.81250\n[33,   400,] loss: 1.54909 acc: 90.86328\n[33,   450,] loss: 1.55396 acc: 90.84722\n[33,   500,] loss: 1.55351 acc: 90.84063\n[33,   550,] loss: 1.55678 acc: 90.79261\n[33,   600,] loss: 1.56102 acc: 90.73438\n[33,   650,] loss: 1.56430 acc: 90.65144\n[33,   700,] loss: 1.55880 acc: 90.61384\n[33,   750,] loss: 1.55586 acc: 90.61458\n[34,    50,] loss: 1.57352 acc: 88.75000\n[34,   100,] loss: 1.54748 acc: 90.03125\n[34,   150,] loss: 1.55728 acc: 90.19792\n[34,   200,] loss: 1.56512 acc: 90.03125\n[34,   250,] loss: 1.55716 acc: 90.08125\n[34,   300,] loss: 1.56065 acc: 90.03646\n[34,   350,] loss: 1.55975 acc: 90.05357\n[34,   400,] loss: 1.56591 acc: 89.99609\n[34,   450,] loss: 1.55312 acc: 90.07639\n[34,   500,] loss: 1.55163 acc: 90.15937\n[34,   550,] loss: 1.55915 acc: 90.16193\n[34,   600,] loss: 1.56963 acc: 90.05729\n[34,   650,] loss: 1.55531 acc: 90.09375\n[34,   700,] loss: 1.56187 acc: 90.08036\n[34,   750,] loss: 1.55878 acc: 90.08958\n[35,    50,] loss: 1.55361 acc: 90.90625\n[35,   100,] loss: 1.55416 acc: 90.79688\n[35,   150,] loss: 1.56297 acc: 90.48958\n[35,   200,] loss: 1.55154 acc: 90.60938\n[35,   250,] loss: 1.53599 acc: 90.99375\n[35,   300,] loss: 1.55449 acc: 90.93229\n[35,   350,] loss: 1.54797 acc: 90.98661\n[35,   400,] loss: 1.54861 acc: 91.02344\n[35,   450,] loss: 1.54937 acc: 91.03819\n[35,   500,] loss: 1.55937 acc: 90.94375\n[35,   550,] loss: 1.55923 acc: 90.87500\n[35,   600,] loss: 1.54784 acc: 90.90885\n[35,   650,] loss: 1.55590 acc: 90.87019\n[35,   700,] loss: 1.55392 acc: 90.85714\n[35,   750,] loss: 1.56070 acc: 90.80208\n[36,    50,] loss: 1.55300 acc: 90.81250\n[36,   100,] loss: 1.55031 acc: 90.96875\n[36,   150,] loss: 1.54824 acc: 91.08333\n[36,   200,] loss: 1.54260 acc: 91.28906\n[36,   250,] loss: 1.55454 acc: 91.16250\n[36,   300,] loss: 1.55763 acc: 91.03646\n[36,   350,] loss: 1.54851 acc: 91.07589\n[36,   400,] loss: 1.55724 acc: 90.99219\n[36,   450,] loss: 1.54824 acc: 91.01736\n[36,   500,] loss: 1.54872 acc: 91.04688\n[36,   550,] loss: 1.55403 acc: 91.00852\n[36,   600,] loss: 1.55791 acc: 90.94531\n[36,   650,] loss: 1.55581 acc: 90.91827\n[36,   700,] loss: 1.55214 acc: 90.92634\n[36,   750,] loss: 1.57171 acc: 90.77917\n[37,    50,] loss: 1.54948 acc: 91.21875\n[37,   100,] loss: 1.54670 acc: 91.25000\n[37,   150,] loss: 1.55227 acc: 91.14583\n[37,   200,] loss: 1.54414 acc: 91.31250\n[37,   250,] loss: 1.54987 acc: 91.25625\n[37,   300,] loss: 1.55446 acc: 91.18750\n[37,   350,] loss: 1.54772 acc: 91.18304\n[37,   400,] loss: 1.54686 acc: 91.20703\n[37,   450,] loss: 1.55115 acc: 91.19444\n[37,   500,] loss: 1.55399 acc: 91.15000\n[37,   550,] loss: 1.55432 acc: 91.09943\n[37,   600,] loss: 1.55147 acc: 91.08073\n[37,   650,] loss: 1.55059 acc: 91.06971\n[37,   700,] loss: 1.55212 acc: 91.05134\n[37,   750,] loss: 1.54836 acc: 91.07083\n[38,    50,] loss: 1.54399 acc: 91.71875\n[38,   100,] loss: 1.54300 acc: 91.76562\n[38,   150,] loss: 1.54212 acc: 91.81250\n[38,   200,] loss: 1.54586 acc: 91.77344\n[38,   250,] loss: 1.54616 acc: 91.70000\n[38,   300,] loss: 1.54633 acc: 91.66146\n[38,   350,] loss: 1.54190 acc: 91.70982\n[38,   400,] loss: 1.54911 acc: 91.64062\n[38,   450,] loss: 1.55314 acc: 91.55208\n[38,   500,] loss: 1.54940 acc: 91.52500\n[38,   550,] loss: 1.54951 acc: 91.50000\n[38,   600,] loss: 1.54859 acc: 91.48438\n[38,   650,] loss: 1.54788 acc: 91.47356\n[38,   700,] loss: 1.54131 acc: 91.51786\n[38,   750,] loss: 1.55058 acc: 91.48542\n[39,    50,] loss: 1.54056 acc: 92.09375\n[39,   100,] loss: 1.55300 acc: 91.46875\n[39,   150,] loss: 1.54439 acc: 91.57292\n[39,   200,] loss: 1.56188 acc: 91.14062\n[39,   250,] loss: 1.55160 acc: 91.08125\n[39,   300,] loss: 1.55509 acc: 90.98438\n[39,   350,] loss: 1.54571 acc: 91.06696\n[39,   400,] loss: 1.55253 acc: 91.04688\n[39,   450,] loss: 1.54610 acc: 91.09722\n[39,   500,] loss: 1.55279 acc: 91.06250\n[39,   550,] loss: 1.54339 acc: 91.13068\n[39,   600,] loss: 1.55693 acc: 91.07031\n[39,   650,] loss: 1.54610 acc: 91.10337\n[39,   700,] loss: 1.54812 acc: 91.11384\n[39,   750,] loss: 1.54025 acc: 91.17708\n[40,    50,] loss: 1.54217 acc: 91.84375\n[40,   100,] loss: 1.53881 acc: 92.06250\n[40,   150,] loss: 1.53944 acc: 92.09375\n[40,   200,] loss: 1.54470 acc: 92.00000\n[40,   250,] loss: 1.54992 acc: 91.81875\n[40,   300,] loss: 1.55288 acc: 91.64583\n[40,   350,] loss: 1.55286 acc: 91.51786\n[40,   400,] loss: 1.54544 acc: 91.52344\n[40,   450,] loss: 1.54856 acc: 91.48958\n[40,   500,] loss: 1.55481 acc: 91.39062\n[40,   550,] loss: 1.55406 acc: 91.32386\n[40,   600,] loss: 1.54083 acc: 91.39062\n[40,   650,] loss: 1.54509 acc: 91.40865\n[40,   700,] loss: 1.54697 acc: 91.40179\n[40,   750,] loss: 1.55041 acc: 91.37292\n----- Train Finished -----\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test(model, testloader):\n    print('------ Test Start -----')\n\n    correct = 0\n    total = 0\n    acc_test=[]\n    loss_test=[]\n    with torch.no_grad():\n        for test_x, test_y in testloader:\n            images, labels = test_x.cuda(), test_y.cuda()\n            output = model(images)\n            loss = criterion(output, labels)\n            _, predicted = torch.max(output.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()    \n            accuracy = 100 * correct / total\n            # 一次迭代的acc_test\n            acc_test.append(accuracy)\n            loss_test.append(loss)\n    accuracy = 100 * correct / total\n    print('Accuracy of the network is: %.2f %%' % accuracy)\n    return acc_test,loss_test","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_test,loss_test = test(net_1, testloader)","execution_count":15,"outputs":[{"output_type":"stream","text":"------ Test Start -----\nAccuracy of the network is: 80.18 %\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef show_acc_curv(acc_test,loss_test,acc_train,loss_train):\n    #train_acc\n    train_loss_x = list(range(len(loss_train)))\n    train_loss_y = loss_train\n    train_acc_x = list(range(len(acc_train)))\n    train_acc_y = acc_train\n    \n    # 测试集\n    # 每一个epoch个 train 对应一个test\n    test_loss_x = train_loss_x[::4]\n    test_loss_y = loss_test[:len(test_loss_x)]\n    test_acc_x = train_acc_x[::4]\n    test_acc_y = acc_test[:len(test_acc_x)]\n    \n    plt.title('CIFAR10 train test loss and acc')\n    \n    plt.plot(train_loss_x, train_loss_y, color='green', label='training loss')\n    plt.plot(train_acc_x, train_acc_y, color='red', label='training accuracy')\n    plt.plot(test_loss_x, test_loss_y, color='Blue', label='testing loss')\n    plt.plot(test_acc_x, test_acc_y, color='Yellow', label='testing accuracy')\n    \n    # 显示图例\n    plt.legend()\n    plt.xlabel('iterations')\n    plt.ylabel('value')\n\n    plt.show()","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_acc_curv(acc_test,loss_test,train_acc ,train_loss)","execution_count":27,"outputs":[{"output_type":"stream","text":"600\n150\n150\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd5xU1fn48c8zZXuhdxEsWGBZmgIqoqKIJViiYkvUr6jRFEsklhg1+tMYNYomRsUWuxAVjYKKqKjYaKIIKlhAkN6215nn98e5szssu8sCOzu7O8/79bqvO3PrOXd2n3vuueeeK6qKMcaYxOGLdwKMMcY0LQv8xhiTYCzwG2NMgrHAb4wxCcYCvzHGJBgL/MYYk2As8JuEICLnicgb8U7HjojIeBGZFe907AoRmS0i58c7HWbHLPC3MiJytojME5FCEVkjIm+IyGHevJtF5JmoZVVEirxlC0Vka41t7eMtc3+N6YEa664SkbtExBe1zFki8omIFIvIzFrSOUhEFnjz54pI/3ry9IyI3LwbhwVVfVJVj9uVdUXk/4nIf3Zn/952Iset1+5uy5jdYYG/FRGRq4CJwO1AZ6An8G/gpHpWy1XVDG9oU2PeecBm4CwRCdaybl9VzQCOAn7lLR+xCbgHuKuWdCYDrwJPAG2B54FX6tjHDolIYFfWMyZRWeBvJUQkG7gF+K2qvqyqRapaoaqvqeqEXdie4IL5dYAAJ9S1rKouBT4GBkRNm6Gq/wXW1LLKKLeI/lNVy4B7gWRgZC3puAwYB1zvXV1M9aavEpEJIrIIKPam3SAiP4hIgYgsFpGxUdupqkKJKnlfIiLficiWmlc1UeudCPwJOMfb/3xvehsRecK7qlolIrdErnhEpI+IfCAieSKyUUSe8zb3gTde7G3rl3Ud06j9H+ZdweWJyBwRGRo170IRWe7l9wcROXMH+6+5bZ+IvCgia0Vkq4jMEpEDouY/IyL3e1eNBd4VXO+o+WNE5FtvP/fh/k7qysdwEfnU288ab7vBqPk5IjJTRDZ76fmTNz0gIn8Rke9FJN87Ft12dNxM/Szwtx7DgRRgaiNt7wjcVcNk4L/Ar+ta0AsWhwLfNXDbfYEvIl/U9RuyyJu+DVX9t5eG272rklOiZp8JHAdke9+XeunIBm4DnhORzvWk43hgMDAQOFdEjq5l/68DdwLPevsf7M16BigB9gaG4E6MF3jzbgOm4a5megAPeNMPj+Tf29ZL9aQNEengbecfQHvgfmC6iLQVkSzcFdUxqprp5fvLHey/Nq8D+wJdgK+Ap2vMPxv4C9AO+Am41UtbJ+BF4FqgA7AKGErdKoHLvWUPBcYAl3jbygZmAq8BXYE+wCxvvQnAad7ybYDxQGk9+zENYIG/9WgPbFTVyp1cb4FXCttao9R7HjBNVfOA54ATRKR9jXW/FJEiYAnwNvBwA/eZAeTVmJYHZO5k2u9T1VWqWgKgqlNUdY2qhlX1OWA5LijX5W+qmqeqy3GBZkA9y1YRke64q5YrVbVYVdfiqtjO9BapAHoBXVW1VFU/2sl8RfwCWKyqz6tqpao+A/xA9dWXAv1EJMXL95Kd2b93nP6jqgWqWgrcDAwWkfSoxV5U1XmqWgE8S/UxOhFYqKpTvXn/ADbUlRFVnauqn3n5+AGYRPUV3lhgparep6plqpqvqnO8eeOB61V1mZfehaq6uUFHz9TJAn/rsQnosAv13YNUtY03/AHA+8f/Je4fHWA2rsrmrBrr9scF67NxVxxpDdxnIZBVY1oWULCTaV8Z/UVEzheRLyInMmB/XAmzLmujPhfjTkgNsSeuampd1L4ewF0hAfwRCALzRGSRiJxXx3Z2pBuwosa0FUB3Vc3H/R6/BdaKyOsi0mdn9i8ifhG506smyqf6ii36mNV1jLoRdfxVNYwr9ddKRPYXkWleNU4+rloysp89qPtqcQ/g+7q2a3aNBf7W4xPcJfDJjbCtX+L+wSeJyFpc0O9CLdU9XinseWAecEMDt78YyI188e4n5HjTa1NXF7JV00VkL+BB4FKgvXej+hvqqXfeCTX3vxIXBNtFnTSzVLU/gFf6Hq+qXXGBeZJXN76zXeGuxp1kovUEfvb284aqHo2rHvkO74qrnv3X9GtcdddRuOqxfbzpDTlma3BB2a3g7m/0qGf5h3FVSfuoahZwY9R+VuKqzGpT3zyziyzwtxJelcyNwAMicrKIpIlIUESOE5E7d3Jz5wGP4ILxAG84HBgSffOvhr8BvxGRjlBVmkwBAoBPRFKirkbeBfwi8ltxLXwux1VPvF/HttcBe+0gzRm4wLrB7V7G40r8jWEd0Ms7QaGqK7203i0iWd5N0n1E5HDczs/wqoMAtnrpCqlqCHdltqO8RLwO9BWRcd5NzrNxwXm6iHQVkV+ISBpQDhQBofr2X8v2M4EyL01puHsDDfU6MEBETvJ+1yuBjvUsn4mrzivy/oYuiZr3P6CniPxORJK8Y3qwN+9R4P+JyN7iDBCRdjuRTlMLC/ytiKreA1yFK3lvwJWWfge80tBtiEhP3I3diaq6NmqYg7sBV2u1gaouxF11XO1NugB38/OfwJHe54e8ZUtxTUzH4wLTucBJXl1xbR4FcsW1vnmxjv1/ibv5OQdXGt0f+Kyh+d6ByUASsFlEInXP5wLpuPsbW3A3wLt484YCc737Hy/jWlr95M27CXfTeauInFrfTlV1A67++xpccL4SONGr4/bjbnyu8eYdgvutd7T/aE/gripW4662Pm7Y4QBVXYdrbXWXt/+e1H+8/4j72ynAlf4nR20rDzgGd6W5HneTPlL/fxfu7/cdIB93byCloek0tRN7EYsxxiQWK/EbY0yCscBvjDEJxgK/McYkGAv8xhiTYFpE51YdOnTQXr16xTsZxhjTosyfP3+jqm7XzLZFBP5evXoxb968eCfDGGNaFBGp+eQ3YFU9xhiTcCzwG2NMgrHAb4wxCcYCvzHGJBgL/MYYk2As8BtjTIKxwG+MMQnGAr8xxsTSyy/D9/W8ROz99+Guu+Cn2nrOjo0W8QCXMcY0Wx99BH/6E2zdCv37Q2YmjBgBffrAzz/DL3/pllu/HjrWeIh29mw46igIh+GWW+Dvf4eRI+HAA918aYwXyG3PAr8xJrEUFrogXVTkgnMkuM6cCf/+N5xyCvTrB6rQpQtkZ8Nf/wpffOEC9IEHQmoq7Lkn7LEH/OUvsGYNDBniAnl+PjzyyPb7Pf10uO02KCiAvDy3/UcfdSeKDz6AK66A3/7WLdu+vUtjejq8+CIcc0yjHgIL/MaYluGNN+DCC13A7NMHSkshIwP22QcOPxwOPhj23bf2dWfMgAkToHNnePvt6ult27ppHTq4oB0MwtSptW/D74feveGTT6C8HCqiXhh3zz1w5ZXuczgMixa50n55udvHv/7lAvhhh22/3T/+0V0pzJzptv3tt+5E0LUrlJRAz567drzq0SLewDVkyBC1vnqMaSbefBO++w4uvhiSkradt3kzvPsufPklDB4MJ57oAmY0VfjsMxfkund3wfrAAyE52ZWG77wTVqyAY491gb2oCFaudKVxnw+OPNLtPxh0wX/xYleC7tQJnnsOevVyQbOoCBYsgP32g//7P3jvPbf/du1ctYrfD3PmuJL1Tz+5Kpc//xnmz4fVq11pe80a+PBDV/K/995t8/Dzz245ERg4EAI7KEcvWgRffQXdukFamlu+Vy93YogREZmvqkO2m26B35hWaP16N/TrV/v8iy5y1RTHHQcHHdTw7a5e7YI1uIB9//0werQLyOCqSV6JesVzt24waBAcfbSbt349PPUU/POf2243M9Ntb8GC+vf/3//CaadtOy0UggsugKefrn/dE06AX/wCzjnHnVASgAV+Y1qT8nLXEqRvX1eqji5tlpa6OuLiYhd4b7nFlWpzcmDAAFcS3muv6uUjgdznc6XeQw91pefvvnP7OeAAVwJPS4Np0+DVV+GGG2DiRFdf3qMH7L23K7G//z6UlblS8rffwjPPwJIlLuBHO/FEl/7ycrfc22/DqlWuOqdXL1c6/vprt2xyspu2YYNLd203PF980dWhA/zjH66KJBRyJ7UffnBpP+EEl68EYoHfmJamstJVPZSWwk03uSqKiHvvhauucp9Hj3ZNBtPT3fc5c2Do0Nq3KeJuTBYXw3XXuSqZ9HQ3FBbCO++46pr67L+/C+YlJfDaa656ZdMmt35BgavPPu64bdd55x13Urj1Vve9oqL2qpEVK1yg79Jlx8cn2rx5LshnZrqbqwawwG9MfKi6kmpZmQuu0cE7Mr+gALKytl/3xhurA2VSkruxefTR7kbmqFGuumL0aLj5ZrdM376u9L50KSxf7uqT99vPjdu1c8H6009d88OTT65uQVIzPf/8J6xdC+ed56atWuXq4CsrXXv0ffZxpfxd8cILLp05Obu2fl02bXI3aMePr71FTYKywG9MLJSXuyZ6Y8e6m5nRNm2CQw5xgThi8GBXGu7Tx1VP/O9/bnrPni6IZ2W5qo/u3WHSJDjpJBf8//Y319qktLR6W3feCX/4gztBrFtXPSxc6AL+kiUxawfeLH3zjasKqnnDOYFZ4DeJa+ZMd5NzZ6sPov34o2um17t39Y3M0lJ3Q3LVqurluneHM890TQtvvdUFo7/9za2Tl+fqsj/91JWsI6691gX7115zLU26dHFVHgD/+U91ybu83FVpzJrlriKuv377B4Iiy/n927emMQmnrsCPqjb7YfDgwWrMLiksVPX5VHv0UF20aPv5n32meuihqi+/XPv6RUWqp56q6kK1aps2qvvuq3rOOapXXOGmJSWpDh6sKqI6YoRqIFC9/F/+sv02S0pUv/xS9a23VCsrq6eHw9WfV65U/e1vVfPydi//JqEB87SWmGoPcJnWYcsW94Slr0b3UytWuJL6mjXuIZnTToNLLnF11l27upuiH33khltvdXXne+0Fbdq4m4zPP++Wuf5696TmzJnuxuiMGa7UnZXl2oD7/a5qZ889XXXLihWuJUptJfKUFFfHXbOeO7papkcPd5PUmBiwqh7T8k2c6J6a3Htv+NWvXJvuyNOO06e7ZnxTpriHhh56yDVnTEtzj+DffLO74bjXXrBs2bbbHTjQBXGfzwX36MAcCrkHlTIyYPjwJsuqMTvD6vhN8zZpkmstctRRO7/uoYfC55+7NuqR+vN99nGP4qvCxx+7B4+6dnWtVV57DX73O1cf/+OPrpT/1luurn7hQjfesAFef921Af/HP9zJxJgWpq7Ab1U9pnm45BI3rq0gogp33OGaPR59tGtS+N13rmpnjz1cYL/sMnjgARfI//tfV7rfuNHdDO3UyZ0EwN04jTy1+te/uuWHD3dVNXvu6YaISDNJY1oZK/GbplFR4apL1qxxDxcFg9XziourHz7ae2/3ea+9XBe1ffq4ljCjR2+7vUDAtSuPePBB+M1vtt9vWZkbamsnH0lXIJBYzR5NwqirxG8vYjFN4557XPXLiBGu+9qNG6vn/fyzG++9t2vnnpzsgn3//u4kEQn6n3/ungD94QcXzIuKXC+G994LZ59d+36Tk+sO+uBOQBb0TYKxqh7TuMLh7VvWgOvyFlyPjk8+6erVb77ZPWYfCfyTJlXX8a9eDbff7h5C6t7d9dQ4YMC220xLcyeSESNilh1jWiML/A0yG3geSAZ6AL8B0uKaomZHFc46y90cffll15HX4YfDsGHuRLB6tQveDz/sgvuZZ8Kpp7q69exst41IZ2HgOhez5ozGxIQFfgAqgW+BfXDBHaACeA24H3gfF+h9QCHwEfBfEq6mbNEiV7p+4QXXkdemTa6t+pgxrmnk5Mluub59t12vRw/XUub3v3ffx41zfceEQq4Xx/Xr3c3WPn2aNDvGJCoL/JQBpwLTcUG/H6DAT8BGXAl/InARLvhPBK4ErgXujEN64+iBB1y3AzV7Xtx3X9cNMLgHof76Vzj+eFft8/33rmnkypWulB8ReZXcmDFNk3ZjTJUEDPzrgBnA90AfXBXOdOAGoBj4CggCBwLjgDFse5guB5YBdwEHAac3VcKbRigEc+e6p0ojLW0iPvjAdXt7ww3upmt6ursKeOEF1xXw8OGuU7K33opP2o0xDZJgzTnvBK6pZfqDuHr7hqoEDgF+BJYAtTyW31L9v//nXh7dtq27uTp0qGuNA651zC23uPk1hcOudYy1kDGm2YhLc04RuVJEFovIVyLyvIikiEg7EXlbRJZ549i9cHIbHwPXAWOB+UAJsAhXwt+ZoA/uCuBxIB/43W6kKQx8iLu/0ETWr3cPLdXmp59cF8P77eeaUl56qXttXnZ29QNQw4bVvq7PZ0HfmBYiZlU9ItId+ANwoKqWiMgU4ExcHco7qnqHiFyLqyyvrRjeiPKAc4A9gaeBSLvuOt5H2iD9gJuAPwNzgFxgPe4qIA3ogKsKOtobot/xuRx4BXelEemrfSjufsJaL50nA8fVWG83hUKuPj4/372w4ttvXV372We7J1b/8x/XPv6tt9zN1nfece3tv/vO1dUfcoh7ctbESAj3txrC3W9KBpKAyAk17M0vBfxAuje0RGW4atcMIPrlNOrNq6yxfAgox5VVM9j2uJidFbOqHi/wf4qLiPm4SHc/8E/gCFVdIyJdgVmqul9929r9qp4/AvfhSteN2aFWJTAJmIW7eugM7I37A10NfAYUASlA5MnTr3H3CAAOxl0xrAOew12FdAYW424sJwPHAMOATkAm7v5DO2Av3D2JT3Enm2KgLTAKdDB8PMc9nJSb6x5iguq3J4FrRhkKVWelQwcX5IcPd10gtGqrcfd4wAWUrVQf+45R0yNDZdRnxZ3Y07z1NnjDJlxQSsIF543esMlbJ4D77YK432pr1FDqbbvYW7amAC7Ql9cyPxNoT3VrtCIvvWnetIqoobLG95C33UDUOFDLNL+XNz/QBsgGCoAtuOCb5OUryRsCXr7XenkLe0MoalwclYc2QKqX9kJvmR0J4E4ANYfkqHxGj6N/t+ghsnzYWz/LGzK9cQbVJxj1hnAtg+7CEFmvLl2BkxpwLOrW5H31qOrPInI3rnlMCTBDVWeISGdVXeMts0ZEYvz241LgCeA0Gjfogzt8l3lDbcpxVUwvAdNwf2h9cVVLvwD2jVr26qjPlbgmo694w+s7SIfg/nFKgBugMABrK+Ft4MMUGHmBq8L51qtSirzZqWNHWLDA9WfzxhvuZFDb6/iarQpcACrABfMlwM9s+w9fGbXcCly12toYp0twJ+f23uDHBbVIwE3DnaR744JoqrdMhjc9gCv1luH+fiOBKcmbn+p9zwfWAJupPilkeOsXe+sHawzRJyA/25/cKmt8jozVS3uet89MXCEnMr3cGxd643bA/lQ3g645tMWdaAtwJ+Fy3NVLhjeO6tIDqD6phqg+QUQPkWlbovKZRvXJDNz/RxHuRF0cdYwCVDfVLqD+YNyURrC7gb8usSzxt8VFvHG4Ys1/gReBf6lqm6jltqjqdvX8InIxcDFAz549B6+IvJFopz0LnAu8A+xCz4/NQimuGikSPDbg/lmScFcDfXB/uBvh7WthxWNwRjZk5bnVVwHf+2F9KqwqhEsmQFo33D9Y9D9+KS4oluDuhYxm58oGW71xGu6fT3BB6Tvvcwbu6uY7bz+bqQ5okaEMF1zycIEt8jnyysEyqoN9WT1piQ5yAS+vvXBXSoNwQcnvpast7qpsHe7YCtuWdqMHwf0OxbiSaifcVUJ7qqspMrxlTcsTxv22+d5QiPtdI6V+ofrqxxf1XXZyqLlObYK4v6td1+TdMovI6cAYVb3Q+/5rXJQaRZNW9YzElQa/JSEeuDrtNPf07LKlIMuAt2HD67B2NnSphCyF5PJ6NhC5tC3AlUbb40qYNYcsXDAtwV3WfwGsjNqOH3cZHX1JX1M6LriWe0Ok6iHb23521JDspSsZV9qsOXTC3T7qSUK2UjamFvHolvknYJiIpOGiwyhgHq64dB5whzd+NXZJ+Ab4wNtVAgR9cB2Y9ekD4gP2c0PH39VocRrClWaK2LZkm4wLxuXAG95QgCttl3hD5FK/AFcaSsOVfA8DBuBKKSW4gF8CdMNVafm8fXb0vnelul46Ol2RkpAxJlZiWcf/mYi8CCzA1SN8jrsTmgFMEZELcSeHGD4B9Sgui+fHbhfxVlQEqanVHaNF+pevlx9XvVFXS9okXN1ibOoX62bVI8Y0hZheE6vqTbg2j9HKcKX/JvALXImzc9PsrqmEw+41gTfc4DpES0pyrXU6doStW11f9sYYU4dWXhk60htamHnzXN83vXvXPv/88+Hpp11J/5JL3Pi771yfOCeeCGPHNmlyjTEtSysP/C3UQQe5cVmZK83XNGuW6z5h3jz3QJYxxuwEC/zNWXKye2FJ587Qrx8MHOieul250r2W0IK+MWYXWOBvbsLeU4tt27pujGfPhqVL4bnntl1uyHYttIwxpkEs8Dc3ed5DV3/5C1x5ZfX0lSvdEKn+OeSQ+KTPGNPiWeBvbrZsceO2NZpa7rGHG4wxZjclyFNNLUhdgd8YYxqJBf54ePVV987Za66BTz6B8qguFCzwG2NizAJ/PMye7QL8nXe6uvrOnV3vmFOmwOneg8wW+I0xMWJ1/PGwbh107w5PPuk+33qrezk5uOnHHef62zHGmBiwwB8Pa9dCjx6ujT64vnUefhiOPNK9EctnF2LGmNixwB8P69ZBr17V33v3hjvuiFtyjDGJxYqWsTRxIuTkuCqdb7+F5cth0yb48kvo0iXeqTPGJCgr8cfKJ59UP4B1/vnV0yPVOH37NnmSjDEGLPDHzuOPQ3Y2LF4Mb77pnrgtLnYl/tNOg0GD4p1CY0yCssAfK0uXumqe7t3hwgvjnRpjjKlidfyxsmyZ9Z5pjGmWLPDvqgsvhKOOqn1eYSGsWePeimWMMc2MVfXsqscfd+NwePt29x9/7MYDBzZtmowxpgEs8O+uH3+Evfd2n7/+GhYsgAcecF0nj2yBr300xrR6Fvh31y23wJw5kJHhgn447PrZefBBSEuLd+qMMWY7Fvh3VZcuruuFp55y39PS4KyzYMIE189Oamp802eMMXWwwL+rSkrcODvb9ayZm2slfGNMi2CtenaFKhQVwfXXw+bNrpM1C/rGmBbCAv+uKC+HykpXr289aRpjWhiLWruisNCNMzLimw5jjNkFFvh3hQV+Y0wLZoF/VxQVuXF6enzTYYwxu8ACf11UYepUmD/ffa+shJdfhgsuqO6qwUr8xpgWyJpz1mXWLDj1VPcE7q9+BZMnuyqepCQ47DAYN86NjTGmhbHAX5fly924vBweewzOPRf693cPafXoEdekGWPM7rDAX5dIPf4VV8DgwS7wG2NMK2CBvy6Rlju3327dLxhjWhW7uVuXoiIQgZSUeKfEGGMalQX+uhQVuVY7IvFOiTHGNKqYBn4RaSMiL4rINyLytYgMF5F2IvK2iCzzxm1jmYZdVlho7fSNMa1SrOv47wPeVNXTRCQJSAOuB95R1TtE5FrgWuCaGKdj5xUVWeA3LV5FRQWrVq2itLQ03kkxMZSSkkKPHj0IBoMNWj5mgV9EsoDDgfMBVLUcKBeRk4AjvMWeBGbRXAO/PaBlWrhVq1aRmZlJr169EKu2bJVUlU2bNrFq1Sp69+7doHViWdWzF7ABeEJEPheRR0UkHeisqmsAvHGn2lYWkYtFZJ6IzNuwYUMMk1kHq+oxrUBpaSnt27e3oN+KiQjt27ffqau6WAb+ADAIeFBVBwJFuGqdBlHVSao6RFWHdOzYMVZprJtV9ZhWwoJ+67ezv3EsA/8qYJWqfuZ9fxF3IlgnIl0BvPH6GKZh16xb516raIHfmN2ydetW/v3vf+/Suscffzxbt26td5kbb7yRmTNn7tL2a+rVqxcbN25slG01dzEL/Kq6FlgpIvt5k0YBS4D/Aed5084DXo1VGnbJnDmw//6uy4bhw+OdGmNatPoCfygUqnfd6dOn06ZNm3qXueWWWzj66KN3OX2JKtbt+H8PPCsiXwIDgNuBO4BjRGQZcIz3vXl4+23X82abNrBkCfzpT/FOkTEt2rXXXsv333/PgAEDmDBhArNmzeLII4/k7LPPJicnB4CTTz6ZwYMH07dvXyZNmlS1bqQEvnz5cg444AAuuugi+vbty+jRoynx3nl9/vnn8+KLL1Ytf9NNNzFo0CBycnL45ptvANiwYQPHHHMMgwYN4pJLLmHPPffcYcn+nnvuoV+/fvTr14+JEycCUFRUxAknnEBubi79+vVj8uTJVXk88MAD6d+/P1dffXXjHsAYiWlzTlVdCAypZdaoWO53l7z3HowdC716wf/+B/vuG+8UGdOornjzChauXdio2xzQZQATx0ysc/4dd9zBV199xcKFbr+zZs1izpw5fPXVV1UtUB5//HHatWtHSUkJBx10EL/85S9p3779NttZtmwZzz//PI888ghnnHEGL730EufW0n9Whw4dWLBgAf/+97+5++67efTRR/nrX//KUUcdxXXXXcebb765zcmlNvPnz+eJJ57gs88+Q1UZOnQoI0eO5IcffqBbt25MmzYNgLy8PDZv3szUqVP55ptvEJEdVk01F/bkLri+96++Gjp1gpkzLegbE0MHH3zwNs0O77//fnJzcxk2bBgrV65k2bJl263Tu3dvBgwYAMDgwYNZHuk9t4ZTTz11u2Vmz57NmWeeCcCYMWNo27b+Z0Znz57NKaecQnp6OhkZGZx66ql8+OGH5OTkMHPmTK655ho+/PBDsrOzycrKIiUlhfHjx/Pyyy+Tlpa2s4cjLqyTNoDnnoMFC+CJJ6B793inxpiYqK9k3pTSoxpNzJo1i5kzZ/LJJ5+QlpbGEUccUWuzxOTk5KrPfr+/qqqnruX8fj+VlZWAa+e+M+pavk+fPsyfP5/p06dz3XXXMXr0aG688UbmzJnDO++8wwsvvMC//vUv3n333Z3aXzwkdom/qAimTIGLLnI3cs85J94pMqZVyczMpKCgoM75eXl5tG3blrS0NL755hs+/fTTRk/DYYcdxpQpUwCYMWMGW7ZsqXf5ww8/nFdeebzcEmAAACAASURBVIXi4mKKioqYOnUqI0aMYPXq1aSlpXHuuedy9dVXs2DBAgoLC8nLy+P4449n4sSJVVVazV1il/j/+Ed4+GH3ecoUaODjzsaYhmnfvj2HHnoo/fr147jjjuOEE07YZv6YMWN46KGH6N+/P/vttx/Dhg1r9DTcdNNNnHXWWUyePJmRI0fStWtXMjMz61x+0KBBnH/++Rx88MEAjB8/noEDB/LWW28xYcIEfD4fwWCQBx98kIKCAk466SRKS0tRVe69995GT38syM5eBsXDkCFDdN68eY2/4aOPhnfecZ9bwHEwZmd9/fXXHHDAAfFORlyVlZXh9/sJBAJ88sknXHrppS2mZL4zavutRWS+qm7XwCaxS/xJSW781lvxTYcxJmZ++uknzjjjDMLhMElJSTzyyCPxTlLcJXbg/+knOPlkGD063ikxxsTIvvvuy+effx7vZDQriX1zd+VK2GOPeKfCGGOaVGIH/uJi63rZGJNwEjfwq0JlZXU9vzHGJIjEDfwVFW5sTTiNMQkmcQN/ebkbW4nfmJhpSd0yJ5LEDfxW4jcm5qxb5u1FupKIpx0GfhHpLCKPicgb3vcDReTC2CctxiKB30r8xsRMS+qW+dJLL2XIkCH07duXm266qWr63LlzOeSQQ8jNzeXggw+moKCAUCjE1VdfTU5ODv379+ef//znNmkGmDdvHkcccQQAN998MxdffDGjR4/m17/+NcuXL2fEiBEMGjSIQYMG8fHHH1ft78477yQnJ4fc3Nyq4zdo0KCq+cuWLWPw4MG79bs0pB3/f4AngD9735cCk4HHdmvP8Rap6rESv0kUV1wBjf3E6oABMLF1dMt822230a5dO0KhEKNGjeLLL79k//33Z9y4cUyePJmDDjqI/Px8UlNTmTRpEj/++COff/45gUCAzZs37/BQzZ8/n9mzZ5OamkpxcTFvv/02KSkpLFu2jLPOOot58+bxxhtv8Morr/DZZ5+RlpbG5s2badeuHdnZ2SxcuJABAwbwxBNPcP755+9wf/VpSFVPB1WdAoQBVLUSqP8arSWwqh5j4qK5dss8ZcoUBg0axMCBA1m8eDFLlizh22+/pWvXrhx00EEAZGVlEQgEmDlzJr/5zW8IBFzZuV27djvM99ixY0lNTQWgoqKCiy66iJycHE4//XSWLFkCwMyZM7nggguquneObHf8+PE88cQThEIhJk+ezNlnn73D/dWnISX+IhFpDyiAiAwD8nZrr82B3dw1iaaeknlTao7dMv/444/cfffdzJ07l7Zt23L++edXdbxW24vM65oeCAQIh8MA2+UjOt/33nsvnTt35osvviAcDpOSklLvdn/5y19WXbkMHjx4uyuindWQEv9VuPfk7i0iHwFP4V6p2LJZid+YmGsp3TLn5+eTnp5OdnY269at44033gBg//33Z/Xq1cydOxeAgoICKisrGT16NA899FDVySVS1dOrVy/mz58PwEsvvVRnmvLy8ujatSs+n4+nn3666kb36NGjefzxxykuLt5muykpKRx77LFceumlXHDBBbt9THYY+FV1ATASOAS4BOirql/u9p7jzW7uGhNz0d0yT5gwYbv5Y8aMobKykv79+/OXv/wlZt0yz5gxg0GDBvHGG2/U2i1zbm4uAwcOpG/fvvzf//0fhx56KABJSUlMnjyZ3//+9+Tm5nLMMcdQWlrK+PHj6dmzJ/379yc3N5fnnnuual+XX345I0aMwO/315mmyy67jCeffJJhw4axdOnSqquBMWPGMHbsWIYMGcKAAQO4++67q9Y555xzEBFGN0LfYjvslllEfl3bdFV9arf33kAx6Zb5s89g2DCYNg2OP75xt21MM2HdMreebpnvvvtu8vLyuPXWW2ud39jdMh8U9TkF96L0Bbgqn5bLSvzGJITW0C3zKaecwvfff99or3XcYeBX1W3q80UkG3i6UfYeT9ac05iE0Bq6ZZ46dWqjbm9XntwtBvZt1FTEg93cNcYkqB2W+EXkNbymnLgTxYHAlFgmqklYVY8xJkE1pI7/7qjPlcAKVV0Vo/Q0HavqMcYkqIbU8b/fFAlpclbiN8YkqDrr+EWkQETyaxkKRCS/KRMZE1biNybmdqdbZoCJEydWPcwEDeuquSGWL19Ov379dns7LVWdgV9VM1U1q5YhU1WzmjKRMWElfmNirrEDf0O6ajY71uBWPSLSSUR6RoZYJqpJWKseY2KuZrfMAHfddRcHHXQQ/fv3r+r+uKioiBNOOIHc3Fz69evH5MmTuf/++1m9ejVHHnkkRx55JNCwrprnzp1L//79GT58OBMmTNhhyb60tJQLLriAnJwcBg4cyHvvvQfA4sWLOfjggxkwYAD9+/dn2bJltaazJWpIq56xwD+AbsB6YE/ga6BvbJMWY1bVYxJMHHpl3q5b5hkzZrBs2TLmzJmDqjJ27Fg++OADNmzYQLdu3Zg2bRrg+rLJzs7mnnvu4b333qNDhw7bbbuurpovuOACJk2axCGHHMK11167wzw88MADACxatIhvvvmG0aNHs3TpUh566CEuv/xyzjnnHMrLywmFQkyfPn27dLZEDSnx3woMA5aqam/ck7sfxTRVTcGqeoxpcjNmzGDGjBkMHDiQQYMG8c0337Bs2TJycnKYOXMm11xzDR9++CHZ2dk73FZtXTVv3bqVgoICDjnkEIAGdV88e/ZsfvWrXwGuU7Y999yTpUuXMnz4cG6//Xb+/ve/s2LFClJTU3cpnc1RQ5pzVqjqJhHxiYhPVd8Tkb/HPGWxlu/dn7bAbxJEc+iVWVW57rrruOSSS7abN3/+fKZPn851113H6NGjufHGG+vdVm1dNTekC+ba0lSbs88+m6FDhzJt2jSOPfZYHn30UY466qidTmdz1JAS/1YRyQA+BJ4Vkftw7flbtjffhMGDwesH2xjT+Gp2y3zsscfy+OOPU1hYCMDPP//M+vXrWb16NWlpaZx77rlcffXVLFiwoNb1d6Rt27ZkZmZWde/8wgsv7HCdww8/nGeffRaApUuX8tNPP7Hffvvxww8/sNdee/GHP/yBsWPH8uWXX9aZzpamISX+D4A2wOXAuUA2cEssExVzP/3keue84454p8SYVi26W+bjjjuOu+66i6+//prhw4cDkJGRwTPPPMN3333HhAkT8Pl8BINBHnzwQQAuvvhijjvuOLp27Vp103VHHnvsMS666CLS09M54ogjdlgdc9lll/Gb3/yGnJwcAoEA//nPf0hOTmby5Mk888wzBINBunTpwo033sjcuXNrTWdL05BumW8CzgA2Ay8AL6rquiZIW5VG75Z54kS48kpYtgz22afxtmtMM5OI3TIXFhaSkZEBuJvLa9as4b777otzqmJvZ7plbsiLWP6qqn2B3+Ja9rwvIjMbmhgR8YvI5yLyuve9nYi8LSLLvHHtL8CMpWnToF8/C/rGtELTpk1jwIAB9OvXjw8//JAbbrgh3klqdnamd871wFpgE9BpJ9a7HNf8M+Ja4B1V3Rd4x/vedAoL4f334bjjmnS3xpimMW7cOBYuXMhXX33FtGnT6NixY7yT1OzsMPCLyKUiMgsXpDsAF6lq/4ZsXER6ACcAj0ZNPgl40vv8JHDyziR4t73zjmvKaW/dMsYkqIbc3N0TuEJVd+XRj4nAn4DoF1x2VtU1AKq6RkRqvXoQkYuBiwF69mzEB4WnTYPMTPDeqWmMMYmmIXX81+5K0BeRE4H1qjp/VxKmqpNUdYiqDmm0SzVVmD4dRo+2J3aNMQmrISX+XXUoMFZEjse9qzdLRJ4B1olIV6+03xV376BpLFoEP/9s1TzGmIS2K69ebBBVvU5Ve6hqL+BM4F1VPRf4H3Cet9h5wKuxSsN23nzTjceMabJdGpPImmu3zIkuZoG/HncAx4jIMuAY73vT+Owz14SzW7cm26Uxicy6ZYbKyubX0UGTBH5VnaWqJ3qfN6nqKFXd1xtvboo0ADB/vuumwRjTJJprt8yFhYWMGjWKQYMGkZOTw6uvVlc8PPXUU/Tv35/c3NyqztvWrVvHKaecQm5uLrm5uXz88cfbvczl7rvv5uabbwbgiCOO4Prrr2fkyJHcd999vPbaawwdOpSBAwdy9NFHs27duqp0RLqE7t+/Py+99BKPPfYYV155ZdV2H3nkEa666qrG+kmA2NbxNy+bNsGKFXDZZfFOiTFxcgXQyP0yMwDXeK92zbVb5pSUFKZOnUpWVhYbN25k2LBhjB07liVLlnDbbbfx0Ucf0aFDBzZvduXSP/zhD4wcOZKpU6cSCoUoLCxky5Yt9R6ZrVu38v777s21W7Zs4dNPP0VEePTRR7nzzjv5xz/+wa233kp2djaLFi2qWi4pKYn+/ftz5513EgwGeeKJJ3j44Yfr/xl2UuIE/khnSlbiNyZuortlBlfiXbZsGSNGjODqq6/mmmuu4cQTT2TEiBE73FZDu2V+/fXXt1tXVbn++uv54IMP8Pl8/Pzzz6xbt453332X0047repE065dOwDeffddnnrqKcD1BJqdnb3DwD9u3Liqz6tWrWLcuHGsWbOG8vJyevfuDcDMmTO36UiubVvXkcFRRx3F66+/zgEHHEBFRQU5OTk7PB47I/ECv/cHZ0ziiX+/zM2lW+Znn32WDRs2MH/+fILBIL169aK0tBRVRUQatI1AIEA4HK76Xlpaus389PT0qs+///3vueqqqxg7diyzZs2qqhKqa3/jx4/n9ttvZ//99+eCCy5oUHp2Rjxu7sbH/PnQuzd4Z3BjTOw1126Z8/Ly6NSpE8FgkPfee48VK1YAMGrUKKZMmcKmTZsAqqp6Ro0aVdUTZygUIj8/n86dO7N+/Xo2bdpEWVlZrVcW0fvr3r07AE8++WTV9NGjR/Ovf/2r6nvkKmLo0KGsXLmS5557jrPOOqvB+W+oxAr8gwbFOxXGJJTobpknTJjA6NGjOfvssxk+fDg5OTmcdtppFBQUsGjRoqr32952221VHatFumWO3NxtiMcee4yLL76Y4cOHo6q1dst8zjnnMG/ePIYMGcKzzz7L/vvvD0Dfvn3585//zMiRI8nNza26qXrffffx3nvvkZOTw+DBg1m8eDHBYJAbb7yRoUOHcuKJJ1ZtozY333wzp59+OiNGjNjmfsUNN9zAli1b6NevH7m5udt0PX3GGWdw6KGHVlX/NKYddsvcHOx2t8z5+ZCdDbfdBtdf33gJM6aZs26ZW263zCeeeCJXXnklo0aNatDyjdotc6uwbJkb13NGNsa0Di29W+atW7fSp08fUlNTGxz0d1Zi3NxdutSN+/SJbzqMMTE3bty4bVrUtDRt2rRhaSRmxUhilPiXLgUR2HvveKfEGGPiLnECf8+ekJoa75QY0+Rawn08s3t29jdOnMBv1TwmAaWkpLBp0yYL/q2YqrJp0yZSUlIavE7rr+NXdYHf63PDmETSo0cPVq1axYYNG+KdFBNDKSkp9OjRo8HLt/7Av2GDa85pJX6TgILBYFX3AMZEtP6qnsjd8X33jW86jDGmmUicwG8lfmOMARIl8AeDsOee8U6JMcY0C60/8K9e7d64FWj9tzOMMaYhWn/gX7cOOneOdyqMMabZSIzA36lTvFNhjDHNRmIEfivxG2NMldYd+MNh147fAr8xxlRp3YF/yxYIhayqxxhjorT+wA/2ukVjjImSGIE/Bq8uM8aYlioxAn+bNvFNhzHGNCOtO/Bv3erGVuI3xpgqrTvwW1WPMcZsJzECv1X1GGNMldYd+LduhaQke+WiMcZEad2Bf8sWV80jEu+UGGNMs9G6A/+998LChfFOhTHGNCutu6/itDQ3GGOMqdK6S/zGGGO2Y4HfGGMSTMwCv4jsISLvicjXIrJYRC73prcTkbdFZJk3tkb2xhjThGJZ4q8E/qiqBwDDgN+KyIHAtcA7qrov8I733RhjTBOJWeBX1TWqusD7XAB8DXQHTgKe9BZ7Ejg5VmkwxhizvSap4xeRXsBA4DOgs6quAXdyAKyzfGOMaUIxD/wikgG8BFyhqvk7sd7FIjJPROZt2LAhdgk0xpgEE9PALyJBXNB/VlVf9iavE5Gu3vyuwPra1lXVSao6RFWHdOzYMZbJNMaYhBLLVj0CPAZ8rar3RM36H3Ce9/k84NVYpcEYY8z2Yvnk7qHAr4BFIhLpN+F64A5giohcCPwEnB7DNBhjjKkhZoFfVWcDdfWONipW+zXGGFM/e3LXGGMSjAV+Y4xJMBb4jTEmwVjgN8aYBGOB3xhjEowFfmOMSTAW+I0xJsFY4DfGmARjgd8YYxKMBX5jjEkwFviNMSbBWOA3xpgEY4HfGGMSjAV+Y4xJMBb4jTEmwVjgN8aYBGOB3xhjEowFfmOMSTAW+I0xJsFY4DfGmARjgd8YYxKMBX5jjEkwFviNMSbBWOA3xpgEY4HfGGMSjAV+Y4xJMBb4jTEmwVjgN8aYBGOB3xhjEowFfmOMSTAW+I0xJsFY4DfGmAQTiHcCYmne6nlsLN7IgC4DyErOIjWQiojEO1nGGBNXrTrw3/nGc/x3wZsQKIVgCRIsJyM1iYxgBhlJmWQkZZAezCAjKYOMYCbpSemkBdLxiY+wKunBdPziDlHAF0QQwpUB8tZlU7ChLVLajpISoW2HMjp0LyCzTRnpGSFUfYTKgwTCGYTKkygv81FZ7ic1o4I27ctITa8kKTmMP6CIQGF+gPUrswj6/bTrECJcEWTrxjQqyvz4/eDzK34/BPyCz6f4A+D3Q2pqmPYdQyQlKcVFfvK2BNiwNonCfD/+AAS8dQNBSAr4SAr6CAaFgB8CQQgEwO9X/AElKShuSIaKMh/ffp3EyuUBunQL03PPMElJ4BcfPp/g84HPJyhhQloBEqZj+wDt2gTI3xpg5SolFFL8gTBZ2WHatgtTXORj0wY/KalKp86KzwflpT5KS6G83EdZqVBWBoGAkJamZKQLaelKKCTkb/VRUQFJSUIwSNWQlOTSHAxCUiBQ9bvl5ysFhe74VobClBb78RGkbVto08blG6C4GDZsgLQ0N23NGti4EbKzoW1bN83nc8c6MlaFLVtg61Zo1w66dXNpCYfduhs3unU7d3brlJVBSYnbV1mZG9LToWNHSEqCUMgN4XD155pDZF5Sktu2CGzaVD1UVLi0tGtXne5169x+O3SArCwoL68eQiGXhuRkKCx0y6Wmunxs3gx5eW6drCwoLXXzI8c8P98NXbpAz54uX5E0hMNuAOja1eVRxOU5cswiecjOdsdn9Wp47z2XlkMOceuFQm570UN5ee3TVN02VaGoyO27WzfIzHT7q6iAHj0gIwNWrnS/sapLF7hj1batOx5r17q/h+RkN5SUuH106QLdu7tjUVDg8ujzuX1kZbn0Ro5TaambF/T+v4JB6NSp+rf+/nt3LCor3T4yM93y5eXVfx/Z2bDXXpCSErvY2KoDf5u5d8DD91R9V6DAG5qHMATKoDI13glpJGHiVnsoleAvhbAfwkmAv+5lk/PAXwHFHWKYnhAgoIlbmyrJhWhYoCK9lplhJLkALc3ebnpMjlmsttvAffuz1hEqaguVDYzmEiZ5v/fpcNGvePqUpzmy95GNmqS4BH4RGQPch/vvfFRV74jFfi69JIlRR7qzcOSMXF5efbbf0VhxxRefQCgcBlF8fqV7d6Vz91IC6XlkZQZY/TOsXBEgL89Hfp7g84cJJoeQQCnB5BBJyWGCQaWwwM/mDQFKSvyUlwnlZT7Ky4U27TbRbc8iwoTYstGPL1hJdodiklIqCYfFlfpCEAqJ+14J4bC4Uv7mJCorfKSkVZCeVU77ziWkZVYQCivhkBAKueUrK6G8MkxlJYQqxQ0hIRzyEar0UVkpVJb7qKwEROm292Y69Mhjy/pUNq9LJ1QphMOgqoQVNAzgIyBBwiEfBfkBCvMCpGYV07ZzkSsFV/opzk+hKC+FpNRyMtqWUF7mp3BzGooSTAoRSKp0Q7ASf1KIcEgoKwlQXhqkvCSI+EOkZpThC4QIVbq0hit9VNb4XFEhVFYIfj+kZ5eQlFrhTgJAMLWUSi2jtCiVkvw0SvNTqawIkN3pc9LbFlJZHiBU6SezfT6pWSWUFaVQWpiChn1oWNCwEA77UBVQSMksISm9hJL8VAo3ZREOC6CkZhWTll1ESUEqBZuyECCQXEEgyRuSK/AHQpSXJlG8NZ1wyI9ICPErIor4wm7wh/H51AVHn/fZFyJUEaCsKBUNCymZRaRmFZGcWYQvEKK0IJXSgjTKClMJVfpJbZNPILmCsvwMKkpS8AVCBJJC+AMhRKCyLEioIkAwtRx/UjkVZX4qK3ykZZWQlFZORXEK5SVJ+JMq8CdVuL+TigDBtGICKaWUbMmmYH07gillpGYXEwiG8PlARAmFlbwN6eSv7UQgoKRmlpCSWUpyRjEV5UJJQQplBWmUFaWR0XELPXK/JhTys+7rvSkrSMMXCOHzh7xxGAlU4vNX4vOHqj8HwgSCigDhsB8fEEgpdyX/TW0oL0kmOb0Y8Yco2tSWsqIUMjpuIq39FncSwPsbDgcpL0qnsjSF1Db5JGflUVkJ4Yok7/cKU7K5DUWb2+BPKieYVoKIomGhoiSFsuIUfL4w/uRy/MEK/MFKUPd/FQ75CVX4Kd7chsL1HUjOLKLdnqtIyc5H/GHCFQHKS1JABX+wEl+gEn8wRHlhGvlrOpGUUUzffcbQMb1jo8dGUdVG32i9OxTxA0uBY4BVwFzgLFVdUtc6Q4YM0Xnz5jVRCo0xpnUQkfmqOqTm9Hhc+xwMfKeqP6hqOfACcFIc0mGMMQkpHoG/O7Ay6vsqb9o2RORiEZknIvM2bNjQZIkzxpjWLh6Bv7b2lNvVN6nqJFUdoqpDOnZs/DouY4xJVPEI/KuAPaK+9wBWxyEdxhiTkOIR+OcC+4pIbxFJAs4E/heHdBhjTEJq8uacqlopIr8D3sI153xcVRc3dTqMMSZRxaUdv6pOB6bHY9/GGJPoEvexQmOMSVBN/gDXrhCRDcCKXVy9A7CxEZMTT5aX5qm15KW15AMsLxF7qup2zSJbRODfHSIyr7Yn11oiy0vz1Fry0lryAZaXHbGqHmOMSTAW+I0xJsEkQuCfFO8ENCLLS/PUWvLSWvIBlpd6tfo6fmOMMdtKhBK/McaYKBb4jTEmwbTqwC8iY0TkWxH5TkSujXd6dkREHheR9SLyVdS0diLytogs88Zto+Zd5+XtWxE5Nj6p3p6I7CEi74nI1yKyWEQu96a3xLykiMgcEfnCy8tfvektLi/gXoQkIp+LyOve95aaj+UiskhEForIPG9aS81LGxF5UUS+8f5nhsc8L6raKgdcP0DfA3sBScAXwIHxTtcO0nw4MAj4KmrancC13udrgb97nw/08pQM9Pby6o93Hry0dQUGeZ8zcW9cO7CF5kWADO9zEPgMGNYS8+Kl7yrgOeD1lvr35aVvOdChxrSWmpcngfHe5ySgTazz0ppL/C3uTV+q+gGwucbkk3B/GHjjk6Omv6CqZar6I/AdLs9xp6prVHWB97kA+Br3sp2WmBdV1ULva9AblBaYFxHpAZwAPBo1ucXlox4tLi8ikoUr8D0GoKrlqrqVGOelNQf+Br3pqwXorKprwAVUoJM3vUXkT0R6AQNxJeUWmRevemQhsB54W1Vbal4mAn8CwlHTWmI+wJ18Z4jIfBG52JvWEvOyF7ABeMKrgntURNKJcV5ac+Bv0Ju+WrBmnz8RyQBeAq5Q1fz6Fq1lWrPJi6qGVHUA7qVBB4tIv3oWb5Z5EZETgfWqOr+hq9QyLe75iHKoqg4CjgN+KyKH17Nsc85LAFe9+6CqDgSKcFU7dWmUvLTmwN9a3vS1TkS6Anjj9d70Zp0/EQnigv6zqvqyN7lF5iXCuwSfBYyh5eXlUGCsiCzHVXseJSLP0PLyAYCqrvbG64GpuOqOlpiXVcAq7yoS4EXciSCmeWnNgb+1vOnrf8B53ufzgFejpp8pIski0hvYF5gTh/RtR0QEV2f5tareEzWrJealo4i08T6nAkcD39DC8qKq16lqD1XthftfeFdVz6WF5QNARNJFJDPyGRgNfEULzIuqrgVWish+3qRRwBJinZd439GO8d3y43EtSr4H/hzv9DQgvc8Da4AK3Jn9QqA98A6wzBu3i1r+z17evgWOi3f6o9J1GO7y80tgoTcc30Lz0h/43MvLV8CN3vQWl5eo9B1BdaueFpcPXL34F96wOPK/3RLz4qVtADDP+xt7BWgb67xYlw3GGJNgWnNVjzHGmFpY4DfGmARjgd8YYxKMBX5jjEkwFviNMSbBWOA3CUFEPvbGvUTk7Ebe9vW17cuY5sqac5qEIiJHAFer6ok7sY5fVUP1zC9U1YzGSJ8xTcFK/CYhiEikh807gBFeP+5Xeh2w3SUic0XkSxG5xFv+CHHvFHgOWORNe8XrFGxxpGMwEbkDSPW292z0vsS5S0S+8vqOHxe17VlRfbA/6z3tjIjcISJLvLTc3ZTHyCSOQLwTYEwTu5aoEr8XwPNU9SARSQY+EpEZ3rIHA/3UdX8L8H+qutnrumGuiLykqteKyO/UdeJW06m4pzJzgQ7eOh948wYCfXH9rHwEHCoiS4BTgP1VVSNdRRjT2KzEbxLdaODXXrfLn+Eeld/XmzcnKugD/EFEvgA+xXWUtS/1Owx4Xl3vnuuA94GDora9SlXDuC4tegH5QCnwqIicChTvdu6MqYUFfpPoBPi9qg7wht6qGinxF1Ut5O4NHA0MV9VcXP89KQ3Ydl3Koj6HgICqVuKuMl7CvXjjzZ3KiTENZIHfJJoC3OsgI94CLvW6kUZE+ng9PtaUDWxR1WIR2R/3+sWIisj6NXwAjPPuI3TEvWmpzp4UvfcXZKvqdOAKXDWRMY3O6vhNovkSqPSqbP4D3IerZlng3WDdQPVr7qK9CfxGRL7E3aESrAAAAGhJREFU9Yr4adS8ScCXIrJAVc+Jmj4VGI7rRVKBP6nqWu/EUZtM4FURScFdLVy5a1k0pn7WnNMYYxKMVfUYY0yCscBvjDEJxgK/McYkGAv8xhiTYCzwG2NMgrHAb4wxCcYCvzHGJJj/D0zyZJDrHkwnAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}